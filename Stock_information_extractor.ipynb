{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_g8FyFnP0Fvi"
   },
   "source": [
    "# Install finviz package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NfX5nPa1qOb2",
    "outputId": "f921464f-74b9-4a8e-ef19-ddfc4cceb724"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting finviz\n",
      "  Downloading https://files.pythonhosted.org/packages/5d/ef/6b8cb66c238572ec487ad6aad43d8f0bfbcf677190d962972490df4922e2/finviz-1.3.4.tar.gz\n",
      "Requirement already satisfied: lxml in /usr/local/lib/python3.6/dist-packages (from finviz) (4.2.6)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from finviz) (2.23.0)\n",
      "Collecting aiohttp\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9c/c6/c518b46d9bf1ae08c1936d82eae4190455ab073bddbb70ddf371211d3151/aiohttp-3.7.2-cp36-cp36m-manylinux2014_x86_64.whl (1.3MB)\n",
      "\u001b[K     |████████████████████████████████| 1.3MB 5.5MB/s \n",
      "\u001b[?25hRequirement already satisfied: urllib3 in /usr/local/lib/python3.6/dist-packages (from finviz) (1.24.3)\n",
      "Collecting cssselect\n",
      "  Downloading https://files.pythonhosted.org/packages/3b/d4/3b5c17f00cce85b9a1e6f91096e1cc8e8ede2e1be8e96b87ce1ed09e92c5/cssselect-1.1.0-py2.py3-none-any.whl\n",
      "Collecting user_agent\n",
      "  Downloading https://files.pythonhosted.org/packages/c3/ca/15546284f62edfec7666ecb6403a6e77f5db850def37cd36f140d99cce02/user_agent-0.1.9.tar.gz\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->finviz) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->finviz) (2020.6.20)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->finviz) (2.10)\n",
      "Collecting yarl<2.0,>=1.0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/25/8b/f4176c06233f7baed99dcb5aefcb010bfbbe769050579adda63083f2c326/yarl-1.6.2-cp36-cp36m-manylinux2014_x86_64.whl (295kB)\n",
      "\u001b[K     |████████████████████████████████| 296kB 21.4MB/s \n",
      "\u001b[?25hCollecting async-timeout<4.0,>=3.0\n",
      "  Downloading https://files.pythonhosted.org/packages/e1/1e/5a4441be21b0726c4464f3f23c8b19628372f606755a9d2e46c187e65ec4/async_timeout-3.0.1-py3-none-any.whl\n",
      "Collecting multidict<7.0,>=4.5\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/78/a0/7c0f5bf1bdcfe88da60d13ba1fead20cb960ae11a355adafae59907d9ae1/multidict-5.0.0-cp36-cp36m-manylinux2014_x86_64.whl (141kB)\n",
      "\u001b[K     |████████████████████████████████| 143kB 15.6MB/s \n",
      "\u001b[?25hRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.6/dist-packages (from aiohttp->finviz) (20.2.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.5 in /usr/local/lib/python3.6/dist-packages (from aiohttp->finviz) (3.7.4.3)\n",
      "Collecting idna-ssl>=1.0; python_version < \"3.7\"\n",
      "  Downloading https://files.pythonhosted.org/packages/46/03/07c4894aae38b0de52b52586b24bf189bb83e4ddabfe2e2c8f2419eec6f4/idna-ssl-1.1.0.tar.gz\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from user_agent->finviz) (1.15.0)\n",
      "Building wheels for collected packages: finviz, user-agent, idna-ssl\n",
      "  Building wheel for finviz (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for finviz: filename=finviz-1.3.4-cp36-none-any.whl size=15193 sha256=23d2d001f1a047739a80cd57eb9c819fdce301f5791306898ff2f4248cf246f8\n",
      "  Stored in directory: /root/.cache/pip/wheels/6d/fa/7c/4cc075d8af3f8ed083dd112b1a2b09888b9a9a2964c907291f\n",
      "  Building wheel for user-agent (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for user-agent: filename=user_agent-0.1.9-cp36-none-any.whl size=18807 sha256=dcc8e92567af98aa5a38b5b11411c63eb7623fcd4fe7caedf9b6957839e09703\n",
      "  Stored in directory: /root/.cache/pip/wheels/92/80/3f/5d79277825042f2d4d447f594e3fc046f1e506f2b481d364b2\n",
      "  Building wheel for idna-ssl (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for idna-ssl: filename=idna_ssl-1.1.0-cp36-none-any.whl size=3161 sha256=69ddd695e43d1a66ecf450791b02a7a0f38973044d280b1655e403b3b65e4943\n",
      "  Stored in directory: /root/.cache/pip/wheels/d3/00/b3/32d613e19e08a739751dd6bf998cfed277728f8b2127ad4eb7\n",
      "Successfully built finviz user-agent idna-ssl\n",
      "Installing collected packages: multidict, yarl, async-timeout, idna-ssl, aiohttp, cssselect, user-agent, finviz\n",
      "Successfully installed aiohttp-3.7.2 async-timeout-3.0.1 cssselect-1.1.0 finviz-1.3.4 idna-ssl-1.1.0 multidict-5.0.0 user-agent-0.1.9 yarl-1.6.2\n",
      "Requirement already satisfied: nest_asyncio in /usr/local/lib/python3.6/dist-packages (1.4.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install finviz #a package that makes scrapping finviz easier\n",
    "!pip install nest_asyncio #to fix the problem with 'event loop already running' introduced by newer versions of libraries installed with finviz\n",
    "\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n3cQfM2eAHgN"
   },
   "source": [
    "# Filter good stocks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7rpFoSjM0P_o"
   },
   "source": [
    "### Extract tickers\n",
    "The finviz package provides filters to get tickers with specific characteristics. We can specify those characteristics or download everything."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3DGcYzXcpqtu",
    "outputId": "5f0528cc-ab51-49c2-de04-b45e2f607a57"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering stocks..\n",
      "Parsing every stock..\n"
     ]
    }
   ],
   "source": [
    "from finviz.helper_functions.save_data import export_to_db, export_to_csv\n",
    "from finviz.screener import Screener\n",
    "from finviz.main_func import get_news\n",
    "import pandas as pd\n",
    "\n",
    "#below are some filters that can be used to extract tickers from finviz\n",
    "#----------- ta_gap_ +\n",
    "#u for up; u0-20 for more specific up\n",
    "#d for down; d0-20 for more specific down\n",
    " \n",
    "#----------- ta_highlow50d_ +         (50 day high/low)\n",
    "#nl -> new low\n",
    "#a0to3h -> 0-3% above low; a0to5h -> 0-5% above low; a0to10h -> 0-10% above low\n",
    " \n",
    "#----------- ta_pattern_ +\n",
    "#wedgedown, wedgedown2, doublebottom, headandshouldersinv, \n",
    " \n",
    "#----------- ta_perf_ +\n",
    "#4wdown -> month down; 13wdown -> quarter down\n",
    "#d15u -> day -15%; 1w30u -> week -30%\n",
    " \n",
    "filters = [] #when empty, takes the stocks of all the indices\n",
    "print(\"Filtering stocks..\")\n",
    "Screener_obj = Screener(filters=filters, order='ticker')\n",
    "print(\"Parsing every stock..\")\n",
    "Screener_obj.get_ticker_details()\n",
    " \n",
    "# Export the screener results to CSV file\n",
    "Screener_obj.to_csv('stocks.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G8Ygl_Y30Gfn"
   },
   "source": [
    "### Read tickers from .csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DgiciRGx0KOO"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df=pd.read_csv(\"/content/stocks.csv\")\n",
    "df.count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JlwNp7aDbUf8"
   },
   "source": [
    "### Data cleaning\n",
    "Retain only desired indicators and change the representation of numbers to not cause trouble during later stages of processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kGPc6WCtbL-V"
   },
   "outputs": [],
   "source": [
    "df = df[['Ticker', 'Price', 'Inst Own', 'Short Float', 'Target Price', 'Dividend', 'Beta', 'RSI (14)', 'Volatility', 'Volume', 'Market Cap', 'Earnings']]\n",
    " \n",
    "missing_value_mark = -999\n",
    "\n",
    "#replaces capitalization with its digit form\n",
    "def market_cap_to_num(value):\n",
    "  if value[-1] == 'M':\n",
    "    return float(value[:-1])*1000000\n",
    "  elif value[-1] == 'B':\n",
    "    return float(value[:-1])*1000000000\n",
    "  else:\n",
    "    return missing_value_mark\n",
    "\n",
    "#replaces missing volume with -1, and removes commas\n",
    "def volume_to_num(value):\n",
    "  if value == '-':\n",
    "    return -1\n",
    "  else:\n",
    "    return float(value.replace(',', ''))\n",
    " \n",
    "df['Ticker'] = df['Ticker'].replace('-','.') #because zacks doesn't recognize stocks with '-'. Finviz recognize both\n",
    "df['Market Cap'] = df['Market Cap'].map(market_cap_to_num)\n",
    "df['Volume'] = df['Volume'].map(volume_to_num)\n",
    "for col_name in ['Price', 'RSI (14)', 'Beta', 'Dividend', 'Target Price']:\n",
    "  df[col_name] = df[col_name].map(lambda value: float(value) if value != '-' else missing_value_mark)\n",
    "for col_name in ['Short Float', 'Inst Own']:\n",
    "  df[col_name] = df[col_name].map(lambda value: float(value[:-1]) if value[:-1].replace('.','',1).isdigit() else missing_value_mark)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N0YZgidh0T8D"
   },
   "source": [
    "\n",
    "### Filter tickers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "llTU5f7az4Gs"
   },
   "outputs": [],
   "source": [
    "filtered_df = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "QwnNN7Jls8YF",
    "outputId": "008f9306-65c1-401c-cb3d-80dc159d7726"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ticker</th>\n",
       "      <th>Price</th>\n",
       "      <th>Inst Own</th>\n",
       "      <th>Short Float</th>\n",
       "      <th>Target Price</th>\n",
       "      <th>Dividend</th>\n",
       "      <th>Beta</th>\n",
       "      <th>RSI (14)</th>\n",
       "      <th>Volatility</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Market Cap</th>\n",
       "      <th>Earnings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AACQ</td>\n",
       "      <td>9.98</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.00</td>\n",
       "      <td>-999.00</td>\n",
       "      <td>-999.00</td>\n",
       "      <td>-999.00</td>\n",
       "      <td>-999.00</td>\n",
       "      <td>1.42% -</td>\n",
       "      <td>50087.0</td>\n",
       "      <td>7.226900e+08</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>ABBV</td>\n",
       "      <td>89.78</td>\n",
       "      <td>70.8</td>\n",
       "      <td>0.69</td>\n",
       "      <td>109.81</td>\n",
       "      <td>4.72</td>\n",
       "      <td>0.70</td>\n",
       "      <td>36.69</td>\n",
       "      <td>1.78% 1.99%</td>\n",
       "      <td>6307956.0</td>\n",
       "      <td>1.583600e+11</td>\n",
       "      <td>Jul 31 BMO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>ABEO</td>\n",
       "      <td>1.89</td>\n",
       "      <td>53.2</td>\n",
       "      <td>3.15</td>\n",
       "      <td>-999.00</td>\n",
       "      <td>-999.00</td>\n",
       "      <td>1.18</td>\n",
       "      <td>28.08</td>\n",
       "      <td>6.92% 7.38%</td>\n",
       "      <td>1013187.0</td>\n",
       "      <td>1.701900e+08</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>ABIO</td>\n",
       "      <td>5.12</td>\n",
       "      <td>8.6</td>\n",
       "      <td>-999.00</td>\n",
       "      <td>-999.00</td>\n",
       "      <td>-999.00</td>\n",
       "      <td>2.86</td>\n",
       "      <td>42.90</td>\n",
       "      <td>7.08% 7.40%</td>\n",
       "      <td>1423616.0</td>\n",
       "      <td>3.041000e+07</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>AC</td>\n",
       "      <td>36.95</td>\n",
       "      <td>76.8</td>\n",
       "      <td>1.99</td>\n",
       "      <td>-999.00</td>\n",
       "      <td>0.20</td>\n",
       "      <td>1.25</td>\n",
       "      <td>43.38</td>\n",
       "      <td>2.40% 2.48%</td>\n",
       "      <td>6555.0</td>\n",
       "      <td>8.302700e+08</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7506</th>\n",
       "      <td>ZIXI</td>\n",
       "      <td>5.72</td>\n",
       "      <td>69.5</td>\n",
       "      <td>6.39</td>\n",
       "      <td>-999.00</td>\n",
       "      <td>-999.00</td>\n",
       "      <td>1.23</td>\n",
       "      <td>44.17</td>\n",
       "      <td>4.57% 4.45%</td>\n",
       "      <td>521110.0</td>\n",
       "      <td>3.358800e+08</td>\n",
       "      <td>Aug 05 AMC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7514</th>\n",
       "      <td>ZOM</td>\n",
       "      <td>0.10</td>\n",
       "      <td>6.4</td>\n",
       "      <td>2.80</td>\n",
       "      <td>-999.00</td>\n",
       "      <td>-999.00</td>\n",
       "      <td>-0.28</td>\n",
       "      <td>30.51</td>\n",
       "      <td>4.56% 7.62%</td>\n",
       "      <td>26043068.0</td>\n",
       "      <td>5.823000e+07</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7518</th>\n",
       "      <td>ZSL</td>\n",
       "      <td>7.56</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.00</td>\n",
       "      <td>-999.00</td>\n",
       "      <td>-999.00</td>\n",
       "      <td>-999.00</td>\n",
       "      <td>37.19</td>\n",
       "      <td>3.94% 5.90%</td>\n",
       "      <td>1327403.0</td>\n",
       "      <td>-9.990000e+02</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7519</th>\n",
       "      <td>ZTO</td>\n",
       "      <td>31.01</td>\n",
       "      <td>40.0</td>\n",
       "      <td>2.23</td>\n",
       "      <td>-999.00</td>\n",
       "      <td>-999.00</td>\n",
       "      <td>0.31</td>\n",
       "      <td>37.15</td>\n",
       "      <td>3.33% 3.36%</td>\n",
       "      <td>3578565.0</td>\n",
       "      <td>2.404000e+10</td>\n",
       "      <td>Aug 12 AMC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7523</th>\n",
       "      <td>ZUO</td>\n",
       "      <td>9.52</td>\n",
       "      <td>58.6</td>\n",
       "      <td>4.97</td>\n",
       "      <td>13.58</td>\n",
       "      <td>-999.00</td>\n",
       "      <td>-999.00</td>\n",
       "      <td>36.47</td>\n",
       "      <td>4.90% 6.74%</td>\n",
       "      <td>2484618.0</td>\n",
       "      <td>1.100000e+09</td>\n",
       "      <td>Sep 02 AMC</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1544 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Ticker  Price  Inst Own  ...      Volume    Market Cap    Earnings\n",
       "4      AACQ   9.98    -999.0  ...     50087.0  7.226900e+08           -\n",
       "21     ABBV  89.78      70.8  ...   6307956.0  1.583600e+11  Jul 31 BMO\n",
       "24     ABEO   1.89      53.2  ...   1013187.0  1.701900e+08           -\n",
       "28     ABIO   5.12       8.6  ...   1423616.0  3.041000e+07           -\n",
       "35       AC  36.95      76.8  ...      6555.0  8.302700e+08           -\n",
       "...     ...    ...       ...  ...         ...           ...         ...\n",
       "7506   ZIXI   5.72      69.5  ...    521110.0  3.358800e+08  Aug 05 AMC\n",
       "7514    ZOM   0.10       6.4  ...  26043068.0  5.823000e+07           -\n",
       "7518    ZSL   7.56    -999.0  ...   1327403.0 -9.990000e+02           -\n",
       "7519    ZTO  31.01      40.0  ...   3578565.0  2.404000e+10  Aug 12 AMC\n",
       "7523    ZUO   9.52      58.6  ...   2484618.0  1.100000e+09  Sep 02 AMC\n",
       "\n",
       "[1544 rows x 12 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Below are some more filters we can use to constrain the ticker indicators\n",
    "#'Gap' when a stock rises or falls a lot after market closes due to news\n",
    "#'Float' how many stocks are available to buy. Low float -> low volatility -> lower volume\n",
    "#'Short Float' > 25% problematic\n",
    "#              > 40% most traders believe it will go down and sell\n",
    "#'RSI' < 30 -> oversold\n",
    "#      > 80 -> overbought\n",
    " \n",
    " \n",
    "filtered_df = df[(df['Price'] < 100) & (df['RSI (14)'] < 45) & (df['Short Float'] < 7)]\n",
    "filtered_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aS_UAoJdkpue"
   },
   "source": [
    "### Get important news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0fU3FAZ7kojs"
   },
   "outputs": [],
   "source": [
    "#add the 'Important News' column to our dataframe\n",
    "filtered_df['Important News'] = \"-\"\n",
    "\n",
    "#Creates a single string of headlines, seperated by @@@. The @@@ is just a way to mark the end of a headline.\n",
    "def merge_important_headlines(headlines):\n",
    "  headlines_with_seperator_signals = []\n",
    "  for headline in headlines:\n",
    "    headlines_with_seperator_signals.append(headline+'@@@')\n",
    "  return ''.join(headlines_with_seperator_signals) \n",
    "\n",
    "#Keywords that make headlines important\n",
    "keywords = ['offering', 'bankrupt', 'options activity', ' top ', 'implied volatility', 'covid-19', 'contract', 'merge', 'acqui', 'earnings', 'upgrade', 'downgrade', 'reiterate', 'crash', 'debt', 'lawsuit', 'alert', 'FDA', 'approval', 'patent']\n",
    "\n",
    "tickers = filtered_df['Ticker'].tolist()\n",
    "\n",
    "for ticker in tickers:\n",
    "  important_headlines = []\n",
    "  news = get_news(ticker)[:2] #keep first 5 news to keep the 'recent' ones\n",
    "  for headline in list(map(lambda t: t[0], news)): #keep the headlines\n",
    "    if any(x in headline.lower() for x in keywords):\n",
    "      important_headlines.append(headline)\n",
    "  #add important news to dataframe\n",
    "  filtered_df.loc[filtered_df['Ticker'] == ticker, 'Important News'] = merge_important_headlines(important_headlines)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "afd5qvUTq9se"
   },
   "source": [
    "### Get Zacks rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-cq0GtWbrCSz"
   },
   "outputs": [],
   "source": [
    "import requests, time, random\n",
    "from bs4 import BeautifulSoup\n",
    " \n",
    "#add the 'Zacks Rating' column to our dataframe\n",
    "filtered_df['Zacks Rating'] = \"-\"\n",
    "ratings_map = {1 : 'Strong Buy', 2 : 'Buy', 3 : 'Hold', 4 : 'Sell', 5 : 'Strong Sell'}\n",
    "tickers = filtered_df['Ticker'].tolist()\n",
    " \n",
    "for ticker in tickers:\n",
    "  print(ticker)\n",
    "  user_agent = 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_9_3) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/35.0.1916.47 Safari/537.36' #otherwise access forbidden due to non-human\n",
    "  headers = {'User-Agent': user_agent}\n",
    "  response = requests.get('https://www.zacks.com/stock/quote/'+ticker+'?q='+ticker, headers=headers)\n",
    "  #print('response:' + str(response))\n",
    "  soup = BeautifulSoup(response.content, 'html.parser')\n",
    "  rank = soup.find_all('span', class_='z_rank rankrect_NA')\n",
    "  if rank:   #Not rated html\n",
    "    filtered_df.loc[filtered_df['Ticker'] == ticker, 'Zacks Rating'] = '-'\n",
    "  else:\n",
    "    rank = soup.find_all('p', class_='rank_view') #Stock html\n",
    "    if rank:\n",
    "      filtered_df.loc[filtered_df['Ticker'] == ticker, 'Zacks Rating'] = rank[0].text[24]\n",
    "    else:\n",
    "      rank = soup.find_all('span', class_='info-tooltip') #ETF html\n",
    "      try:\n",
    "        if rank:\n",
    "          filtered_df.loc[filtered_df['Ticker'] == ticker, 'Zacks Rating'] = rank[0].next_sibling.string[1]\n",
    "        else: #stock doesn't exist in zacks\n",
    "          filtered_df.loc[filtered_df['Ticker'] == ticker, 'Zacks Rating'] = '-'\n",
    "      except:\n",
    "           filtered_df.loc[filtered_df['Ticker'] == ticker, 'Zacks Rating'] = 'ETF'\n",
    "    \n",
    "  \n",
    "  time.sleep(random.randrange(10, 30, 10) / 1000) #wait a bit to appear more human (ms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1nLs6uaFOYO6"
   },
   "source": [
    "### Get Yahoo Finance rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NLLovknnPA6H"
   },
   "outputs": [],
   "source": [
    "#add the 'Yahoo Finance Rating' column to our dataframe\n",
    "filtered_df['Yahoo Finance Rating'] = \"-\"\n",
    "tickers = filtered_df['Ticker'].tolist()\n",
    "\n",
    "for ticker in tickers:\n",
    "  print(ticker)\n",
    "  user_agent = 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_9_3) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/35.0.1916.47 Safari/537.36' #otherwise access forbidden due to non-human\n",
    "  headers = {'User-Agent': user_agent}\n",
    "  response = requests.get('https://finance.yahoo.com/quote/'+ticker+'?p='+ticker+'&.tsrc=fin-srch', headers=headers)\n",
    "  #print('response:' + str(response))\n",
    "  soup = BeautifulSoup(response.content, 'html.parser')\n",
    "  rank = soup.find('div', class_='Pos(a) T(-2px) W(3px) H(12px) Bdrs(4px) Bgc($primaryColor) ')\n",
    "  if rank == None: #some are locked\n",
    "    filtered_df.loc[filtered_df['Ticker'] == ticker, 'Yahoo Finance Rating'] = \"-\"\n",
    "  elif rank['style'][-3:] == 'px;':\n",
    "    filtered_df.loc[filtered_df['Ticker'] == ticker, 'Yahoo Finance Rating'] = \"Undervalued\"\n",
    "  elif rank['style'][-3:] == '0%;':\n",
    "    filtered_df.loc[filtered_df['Ticker'] == ticker, 'Yahoo Finance Rating'] = \"Near Fair Value\"\n",
    "  elif rank['style'][-3:] == 'x);':\n",
    "    filtered_df.loc[filtered_df['Ticker'] == ticker, 'Yahoo Finance Rating'] = \"Overvalued\"\n",
    "    \n",
    "  time.sleep(random.randrange(2, 6, 1) / 100) #wait a bit to appear more human"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FxlFnGQuxxCC"
   },
   "source": [
    "### Restore original missing value symbol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ieICk0YrxdTd"
   },
   "outputs": [],
   "source": [
    "filtered_df = filtered_df.replace({-999: '-'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UpZLLU6f0a45"
   },
   "source": [
    "### Save to .csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "id": "iQemLFH6yNmb",
    "outputId": "fa9be317-4f59-4ebb-e52d-c6c2bac0d684"
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "    async function download(id, filename, size) {\n",
       "      if (!google.colab.kernel.accessAllowed) {\n",
       "        return;\n",
       "      }\n",
       "      const div = document.createElement('div');\n",
       "      const label = document.createElement('label');\n",
       "      label.textContent = `Downloading \"${filename}\": `;\n",
       "      div.appendChild(label);\n",
       "      const progress = document.createElement('progress');\n",
       "      progress.max = size;\n",
       "      div.appendChild(progress);\n",
       "      document.body.appendChild(div);\n",
       "\n",
       "      const buffers = [];\n",
       "      let downloaded = 0;\n",
       "\n",
       "      const channel = await google.colab.kernel.comms.open(id);\n",
       "      // Send a message to notify the kernel that we're ready.\n",
       "      channel.send({})\n",
       "\n",
       "      for await (const message of channel.messages) {\n",
       "        // Send a message to notify the kernel that we're ready.\n",
       "        channel.send({})\n",
       "        if (message.buffers) {\n",
       "          for (const buffer of message.buffers) {\n",
       "            buffers.push(buffer);\n",
       "            downloaded += buffer.byteLength;\n",
       "            progress.value = downloaded;\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
       "      const a = document.createElement('a');\n",
       "      a.href = window.URL.createObjectURL(blob);\n",
       "      a.download = filename;\n",
       "      div.appendChild(a);\n",
       "      a.click();\n",
       "      div.remove();\n",
       "    }\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "download(\"download_b55155bd-28a9-469b-a5b6-af0259dea932\", \"stocks_05-11-2020.csv\", 81191)"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from google.colab import files\n",
    "from datetime import datetime\n",
    " \n",
    "date = datetime.now().strftime('%d-%m-%Y')\n",
    "filename = \"stocks_\"+date+\".csv\"\n",
    " \n",
    "filtered_df.to_csv(\"/content/\"+filename)\n",
    " \n",
    "#download file\n",
    "files.download(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mOv4g2-F5jMQ"
   },
   "source": [
    "# Find upgrades in Zacks\n",
    "This section assumes that there is a .csv file with the Zacks rating from the past."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WwsKYZ-87GKg"
   },
   "source": [
    "### Extract stocks from Finviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZhwLZZg55iSU"
   },
   "outputs": [],
   "source": [
    "from finviz.helper_functions.save_data import export_to_db, export_to_csv\n",
    "from finviz.screener import Screener\n",
    "from finviz.main_func import get_news\n",
    "import pandas as pd\n",
    "\n",
    "filters = [] \n",
    "print(\"Filtering stocks..\")\n",
    "Screener_obj = Screener(filters=filters, order='ticker')\n",
    "print(\"Parsing every stock..\")\n",
    "Screener_obj.get_ticker_details()\n",
    "\n",
    "Screener_obj.to_csv('stocks.csv')\n",
    "\n",
    "df=pd.read_csv(\"/content/stocks.csv\")\n",
    "df=df[['Ticker']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kJarQmXY7W1a"
   },
   "source": [
    "### Extract current Zacks rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_1y4xWXB6Fs7"
   },
   "outputs": [],
   "source": [
    "import requests, time, random\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "#add the 'Zacks Rating' column to our dataframe\n",
    "df['Zacks Rating'] = \"-\"\n",
    "tickers = df['Ticker'].tolist()\n",
    "\n",
    "#for zacks we need to change the user agent otherwise it detects that it's a spot scrapping information\n",
    "for ticker in tickers:\n",
    "  user_agent = 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_9_3) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/35.0.1916.47 Safari/537.36' #otherwise access forbidden due to non-human\n",
    "  headers = {'User-Agent': user_agent}\n",
    "  response = requests.get('https://www.zacks.com/stock/quote/'+ticker+'?q='+ticker, headers=headers)\n",
    "  #print('response:' + str(response))\n",
    "  soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "  print(ticker)\n",
    "  rank = soup.find_all('span', class_='z_rank rankrect_NA')\n",
    "  if rank:   #Not rated html\n",
    "    df.loc[df['Ticker'] == ticker, 'Zacks Rating'] = '-'\n",
    "  else:\n",
    "    rank = soup.find_all('p', class_='rank_view') #Stock html\n",
    "    if rank:\n",
    "      df.loc[df['Ticker'] == ticker, 'Zacks Rating'] = rank[0].text[24]\n",
    "    else:\n",
    "      rank = soup.find_all('span', class_='info-tooltip') #ETF html\n",
    "      if rank:\n",
    "        df.loc[df['Ticker'] == ticker, 'Zacks Rating'] = rank[0].next_sibling.string[1]\n",
    "      else: #stock doesn't exist in zacks\n",
    "        df.loc[df['Ticker'] == ticker, 'Zacks Rating'] = '-' \n",
    "    \n",
    "  \n",
    "  time.sleep(random.randrange(10, 30, 10) / 1000) #wait a bit to appear more human (ms)\n",
    "\n",
    "#use to create the file for the first time\n",
    "#df['Fresh'] = False\n",
    "#df[['Fresh', 'Ticker', 'Zacks Rating']].to_csv(\"/content/zacks_ratings.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yTywiWY67c1Y"
   },
   "source": [
    "### Compare with previous Zacks ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2hMzBd0z7gpj"
   },
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "\n",
    "files.upload() #choose the file with the old rating on local computer\n",
    "\n",
    "prev_df = pd.read_csv(\"/content/zacks_ratings.csv\")\n",
    "\n",
    "missing_value_mark = -999\n",
    "\n",
    "df['Zacks Rating'] = df['Zacks Rating'].map(lambda value: float(value) if value != '-' else missing_value_mark)     \n",
    "prev_df['Zacks Rating'] = prev_df['Zacks Rating'].map(lambda value: float(value) if value != '-' else missing_value_mark)           \n",
    "df['Fresh'] = prev_df['Zacks Rating'] - df['Zacks Rating'] \n",
    "df['Fresh'] = df['Fresh'].apply(lambda value: True if value > 0 else False)\n",
    "\n",
    "#convert back to '-' to read easier\n",
    "df['Zacks Rating'] = df['Zacks Rating'].map(lambda value: value if value != missing_value_mark else '-')\n",
    "df.to_csv(\"/content/updated_zacks_ratings.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VpWN8SCRBeGm"
   },
   "source": [
    "# Parallel zack fetch test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mKsVtxeWBf9W"
   },
   "outputs": [],
   "source": [
    "from multiprocessing import Process, Pool\n",
    "from functools import partial\n",
    "import time, requests\n",
    "\n",
    "def process_zack_response(response):\n",
    "  \n",
    "  rating = ''\n",
    "\n",
    "  soup = BeautifulSoup(response.content, 'html.parser')\n",
    "  rank = soup.find_all('span', class_='z_rank rankrect_NA')\n",
    "  if rank:   #Not rated html\n",
    "    rating = '-'\n",
    "  else:\n",
    "    rank = soup.find_all('p', class_='rank_view') #Stock html\n",
    "    if rank:\n",
    "      rating = rank[0].text[24]\n",
    "    else:\n",
    "      rank = soup.find_all('span', class_='info-tooltip') #ETF html\n",
    "      if rank:\n",
    "        rating = rank[0].next_sibling.string[1]\n",
    "      else: #stock doesn't exist in zacks\n",
    "        rating = '-' \n",
    "  \n",
    "  return rating\n",
    "\n",
    "def request_wrapper(ticker):\n",
    "  user_agent = 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_9_3) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/35.0.1916.47 Safari/537.36' #otherwise access forbidden due to non-human\n",
    "  headers = {'User-Agent': user_agent}\n",
    "  url = 'https://www.zacks.com/stock/quote/'+ticker+'?q='+ticker\n",
    "  response = requests.get(url, headers = headers)\n",
    "  rating = process_zack_response(response)\n",
    "  return [ticker, rating]\n",
    "\n",
    "df['Zacks Rating'] = \"-\"\n",
    "tickers = df['Ticker'][:1000].tolist()\n",
    "pool = Pool(processes = multiprocessing.cpu_count())\n",
    "results = pool.map(request_wrapper, tickers)\n",
    "\n",
    "for result in results:\n",
    "  ticker = result[0]\n",
    "  rating = result[1]\n",
    "  df.loc[df['Ticker'] == ticker, 'Zacks Rating'] = rating"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VCWdcjM1DPcP"
   },
   "source": [
    "# Stock alerts\n",
    "In this section we can add alerts based on price or other indicators provided by Yahoo Finance. From Yahoo Finance because it updates free information regularly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O2cNMjx0DTaX"
   },
   "source": [
    "### Monitor ticker price (Yahoo finance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jKft622qDR9K"
   },
   "outputs": [],
   "source": [
    "import requests, time, operator, re\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def print_on_same_line(price_dict):\n",
    "  output=''\n",
    "  for k, v in price_dict.items():\n",
    "    output += k + ':' + str(v) + '  '\n",
    "  print('\\r', end='')\n",
    "  print(output, end='')\n",
    "\n",
    "def get_ticker_prices(tickers):\n",
    "\n",
    "  price_dict = dict.fromkeys(tickers)\n",
    "  \n",
    "  for ticker in tickers:\n",
    "    user_agent = 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_9_3) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/35.0.1916.47 Safari/537.36' #otherwise access forbidden due to non-human\n",
    "    headers = {'User-Agent': user_agent}\n",
    "    response = requests.get('https://finance.yahoo.com/quote/'+ticker+'?p='+ticker+'&.tsrc=fin-srch', headers=headers)\n",
    "    #print('response:' + str(response))\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    rank = soup.find('span', class_='Trsdu(0.3s) Fw(b) Fz(36px) Mb(-4px) D(ib)')\n",
    "    price_dict.update({ticker : rank.text})\n",
    "\n",
    "  return price_dict\n",
    "\n",
    "def process_alerts(alerts, price_dict):\n",
    "\n",
    "  alert_tickers=[] #tickers that need to have an alert executed\n",
    "\n",
    "  split_alerts = [] #[['BNGO', '<', '0.5'], ...]\n",
    "  for alert in alerts:\n",
    "    if '<' in alert:\n",
    "      if '=' in alert:\n",
    "        split_alerts.append(re.split('(<=)', alert))\n",
    "      else:\n",
    "        split_alerts.append(re.split('(<)', alert))\n",
    "    elif '>' in alert:\n",
    "      if '=' in alert:\n",
    "        split_alerts.append(re.split('(>=)', alert))\n",
    "      else:\n",
    "        split_alerts.append(re.split('(>)', alert))\n",
    "    else:\n",
    "      split_alerts.append(re.split('(=)', alert))\n",
    "  \n",
    "  for ticker, condition, price in split_alerts:\n",
    "    if condition == '<=':\n",
    "      if operator.le(price_dict[ticker], float(price)):\n",
    "        alert_tickers.append(''.join([ticker, condition, price]))\n",
    "    if condition == '<':\n",
    "      if operator.lt(price_dict[ticker], float(price)):\n",
    "        alert_tickers.append(''.join([ticker, condition, price]))\n",
    "    if condition == '>=':\n",
    "      if operator.ge(price_dict[ticker], float(price)):\n",
    "        alert_tickers.append(''.join([ticker, condition, price]))\n",
    "    if condition == '>':\n",
    "      if operator.gt(price_dict[ticker], float(price)):\n",
    "        alert_tickers.append(''.join([ticker, condition, price]))\n",
    "    if condition == '=':\n",
    "      if operator.eq(price_dict[ticker], float(price)):\n",
    "        alert_tickers.append(''.join([ticker, condition, price]))\n",
    "\n",
    "  return alert_tickers\n",
    "\n",
    "def notify_for_alert(alert_tickers):\n",
    "\n",
    "\n",
    "def monitor_tickers(tickers, alerts):\n",
    "\n",
    "  tickers = [ticker.upper() for ticker in tickers] #make tickers uppercase\n",
    "  alerts = alerts \n",
    "\n",
    "  while True:\n",
    "    \n",
    "    price_dict = get_ticker_prices(tickers)\n",
    "    alert_tickers = process_alerts(alerts, price_dict)\n",
    "    for alert_ticker in alert_tickers:\n",
    "      notify_for_ticker_alert(alert_ticker)\n",
    "    print_on_same_line(price_dict)\n",
    "    time.sleep(5) \n",
    "    \n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hx0S9qy_Tvxr"
   },
   "outputs": [],
   "source": [
    "#example of monitoring some tickers\n",
    "monitor_tickers(['BNGO', 'ATNM'], ['AVGR>0.35','BNGO=0.427','TSLA<=700'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Send alerts to email (under experimentation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gvr1vmoohFKx"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "with open('/content/drive/My Drive/mailjet.txt') as f:\n",
    "    mailjet_contents = f.readlines()\n",
    "\n",
    "mailjet_contents = [x.strip() for x in mailjet_contents]\n",
    "\n",
    "\n",
    "from mailjet_rest import Client\n",
    "import os\n",
    "\n",
    "api_key = mailjet_contents[0]\n",
    "api_secret = mailjet_contents[1]\n",
    "mailjet = Client(auth=(api_key, api_secret), version='v3.1')\n",
    "data = {\n",
    "  'Messages': [\n",
    "    {\n",
    "      \"From\": {\n",
    "        \"Email\": \"christos.pylianidis@wur.nl\",\n",
    "        \"Name\": \"Christos\"\n",
    "      },\n",
    "      \"To\": [\n",
    "        {\n",
    "          \"Email\": \"pylianidis@gmail.com\",\n",
    "          \"Name\": \"Christos\"\n",
    "        }\n",
    "      ],\n",
    "      \"Subject\": message,\n",
    "      \"TextPart\": \"\",\n",
    "      \"CustomID\": \"AppGettingStartedTest\"\n",
    "    }\n",
    "  ]\n",
    "}\n",
    "result = mailjet.send.create(data=data)\n",
    "print(result.status_code)\n",
    "print(result.json())\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
